{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import tensorflow as tf\n",
    "import tensorflow_utils as tf_utils\n",
    "import utils as utils\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from dataset_manager import DataSetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 256\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDIM: 512\n",
      "\tDIS_DIM: 1\n",
      "\tFIXED_GENERATOR: False\n",
      "\tFREQ: 250\n",
      "\tGEN_DIM: 100\n",
      "\tITERS: 100000\n",
      "\tLAMBDA: 0.1\n"
     ]
    }
   ],
   "source": [
    "DIM = 512  # model dimensionality\n",
    "GEN_DIM = 100  # output dimension of the generator\n",
    "DIS_DIM = 1  # outptu dimension fo the discriminator\n",
    "FIXED_GENERATOR = False  # wheter to hold the generator fixed at ral data plus Gaussian noise, as in the plots in the paper\n",
    "LAMBDA = .1  # smaller lambda makes things faster for toy tasks, but isn't necessary if you increase CRITIC_ITERS enough\n",
    "BATCH_SIZE = 256  # batch size\n",
    "ITERS = 100000  # how many generator iterations to train for\n",
    "FREQ = 250  # sample frequency\n",
    "\n",
    "mode = 'wgan-gp'  # [gan, wgan, wgan-gp]\n",
    "dataset = '8gaussians'  # [8gaussians, 25gaussians, swissroll]\n",
    "img_folder = os.path.join('img', mode + '_' + dataset + '_' + str(FIXED_GENERATOR))\n",
    "\n",
    "if mode == 'gan':\n",
    "    CRITIC_ITERS = 1  # homw many critic iteractions per generator iteration\n",
    "else:\n",
    "    CRITIC_ITERS = 5  # homw many critic iteractions per generator iteration\n",
    "\n",
    "if not os.path.isdir(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "utils.print_model_setting(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen/fc-1/add   [256, 512]\n",
      "gen/fc-2/add   [256, 512]\n",
      "gen/fc-3/add   [256, 512]\n",
      "gen/fc-4/add   [256, 100]\n",
      "is_reuse: False\n",
      "disc/fc-1/add   [None, 512]\n",
      "disc/fc-2/add   [None, 512]\n",
      "disc/fc-3/add   [None, 512]\n",
      "disc/fc-4/add   [None, 1]\n",
      "is_reuse: True\n",
      "disc_1/fc-1/add   [256, 512]\n",
      "disc_1/fc-2/add   [256, 512]\n",
      "disc_1/fc-3/add   [256, 512]\n",
      "disc_1/fc-4/add   [256, 1]\n",
      "is_reuse: True\n",
      "disc_2/fc-1/add   [256, 512]\n",
      "disc_2/fc-2/add   [256, 512]\n",
      "disc_2/fc-3/add   [256, 512]\n",
      "disc_2/fc-4/add   [256, 1]\n"
     ]
    }
   ],
   "source": [
    "def Generator(n_samples, real_data_, name='gen'):\n",
    "    if FIXED_GENERATOR:\n",
    "        return real_data_ + (1. * tf.random_normal(tf.shape(real_data_)))\n",
    "    else:\n",
    "        with tf.variable_scope(name):\n",
    "            noise = tf.random_normal([n_samples, 100])\n",
    "            output01 = tf_utils.linear(noise, DIM, name='fc-1')\n",
    "            output01 = tf_utils.relu(output01, name='relu-1')\n",
    "            \n",
    "            output02 = tf_utils.linear(output01, DIM, name='fc-2')\n",
    "            output02 = tf_utils.relu(output02, name='relu-2')\n",
    "            \n",
    "            output03 = tf_utils.linear(output02, DIM, name='fc-3')\n",
    "            output03 = tf_utils.relu(output03, name='relu-3')\n",
    "            \n",
    "            output04 = tf_utils.linear(output03, GEN_DIM, name='fc-4')\n",
    "            \n",
    "            return output04\n",
    "        \n",
    "\n",
    "def Discriminator(inputs, is_reuse=True, name='disc'):\n",
    "    with tf.variable_scope(name, reuse=is_reuse):\n",
    "        print('is_reuse: {}'.format(is_reuse))\n",
    "        output01 = tf_utils.linear(inputs, DIM, name='fc-1')\n",
    "        output01 = tf_utils.relu(output01, name='relu-1')\n",
    "\n",
    "        output02 = tf_utils.linear(output01, DIM, name='fc-2')\n",
    "        output02 = tf_utils.relu(output02, name='relu-2')\n",
    "\n",
    "        output03 = tf_utils.linear(output02, DIM, name='fc-3')\n",
    "        output03 = tf_utils.relu(output03, name='relu-3')\n",
    "\n",
    "        output04 = tf_utils.linear(output03, DIS_DIM, name='fc-4')\n",
    "        \n",
    "        return output04\n",
    "    \n",
    "real_data = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "fake_data = Generator(BATCH_SIZE, real_data)\n",
    "\n",
    "disc_real = Discriminator(real_data, is_reuse=False)\n",
    "disc_fake = Discriminator(fake_data)\n",
    "\n",
    "if mode == 'wgan' or mode == 'wgan-gp':\n",
    "    # WGAN loss\n",
    "    disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "    gen_cost = - tf.reduce_mean(disc_fake)\n",
    "\n",
    "    # WGAN gradient penalty\n",
    "    if mode == 'wgan-gp':\n",
    "        alpha = tf.random_uniform(shape=[BATCH_SIZE, 1], minval=0., maxval=1.)\n",
    "        interpolates = alpha*real_data + (1.-alpha) * fake_data\n",
    "        disc_interpolates = Discriminator(interpolates)\n",
    "        gradients = tf.gradients(disc_interpolates, [interpolates][0])\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "        gradient_penalty = tf.reduce_mean((slopes - 1)**2)\n",
    "        \n",
    "        disc_cost += LAMBDA * gradient_penalty\n",
    "elif mode == 'gan':\n",
    "    gen_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake, labels=tf.ones_like(disc_fake)))\n",
    "    \n",
    "    disc_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake, labels=tf.zeros_like(disc_fake)))\n",
    "    disc_cost += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_real, labels=tf.ones_like(disc_real)))\n",
    "    disc_cost /= 2.\n",
    "    \n",
    "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='disc')\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='gen')\n",
    "\n",
    "if mode == 'wgan-gp':\n",
    "    disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(disc_cost, var_list=disc_vars)\n",
    "    \n",
    "    if len(gen_vars) > 0:\n",
    "        gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(gen_cost, var_list=gen_vars)\n",
    "    else:\n",
    "        gen_train_op = tf.no_op()\n",
    "        \n",
    "elif mode == 'wgan':\n",
    "    disc_train_op = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(disc_cost, var_list=disc_vars)\n",
    "    \n",
    "    if len(gen_vars) > 0:\n",
    "        gen_train_op = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(gen_cost, var_list=gen_vars)\n",
    "    else:\n",
    "        gen_train_op = tf.no_op()\n",
    "        \n",
    "    # build an op to do the weight clipping\n",
    "    clip_bounds = [-0.01, 0.01]\n",
    "    clip_ops = [var.assign(tf.clip_by_value(var, clip_bounds[0], clip_bounds[1])) for var in disc_vars]\n",
    "    clip_disc_weights = tf.group(*clip_ops)\n",
    "    \n",
    "elif mode == 'gan':\n",
    "    disc_train_op = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.5).minimize(disc_cost, var_list=disc_vars)\n",
    "    \n",
    "    if len(gen_vars) > 0:                                                        \n",
    "        gen_train_op = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.5).minimize(gen_cost, var_list=gen_vars)\n",
    "    else:\n",
    "        gen_train_op = tf.no_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_image(sess, true_dist, idx):\n",
    "    # generates and saves a plot of the true distribution, the generator, and the critic\n",
    "    N_POINTS = 128\n",
    "    RANGE = 2\n",
    "    \n",
    "    points = np.zeros((N_POINTS, N_POINTS, 2), dtype='float32')\n",
    "    points[:, :, 0] = np.linspace(-RANGE, RANGE, N_POINTS)[:, None]\n",
    "    points[:, :, 1] = np.linspace(-RANGE, RANGE, N_POINTS)[None, :]\n",
    "    points = points.reshape((-1, 2))\n",
    "    \n",
    "    if FIXED_GENERATOR is not True:\n",
    "        samples = sess.run(fake_data, feed_dict={real_data: points})\n",
    "    disc_map = sess.run(disc_real, feed_dict={real_data: points})\n",
    "    \n",
    "    plt.clf()\n",
    "    x = y = np.linspace(-RANGE, RANGE, N_POINTS)\n",
    "    plt.contour(x, y, disc_map.reshape((len(x), len(y))).transpose())\n",
    "    plt.colorbar()  # add color bar\n",
    "    \n",
    "    plt.scatter(true_dist[:, 0], true_dist[:, 1], c='orange', marker='+')\n",
    "    if FIXED_GENERATOR is not True:\n",
    "        plt.scatter(samples[:, 0], samples[:, 1], c='green', marker='*')\n",
    "        \n",
    "    plt.savefig(os.path.join(img_folder, str(idx).zfill(3) + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset iterator\n",
    "def inf_train_gen():\n",
    "    if dataset == '8gaussians':\n",
    "        scale = 2.\n",
    "        centers = [(1.,0.), \n",
    "                   (-1.,0.), \n",
    "                   (0., 1.), \n",
    "                   (0.,-1.),\n",
    "                   (1./np.sqrt(2), 1./np.sqrt(2)),\n",
    "                   (1./np.sqrt(2), -1/np.sqrt(2)), \n",
    "                   (-1./np.sqrt(2), 1./np.sqrt(2)), \n",
    "                   (-1./np.sqrt(2), -1./np.sqrt(2))]\n",
    "        \n",
    "        centers = [(scale*x, scale*y) for x, y in centers]\n",
    "        while True:\n",
    "            batch_data = []\n",
    "            for _ in range(BATCH_SIZE):\n",
    "                point = np.random.randn(2) * .02\n",
    "                center = random.choice(centers)\n",
    "                point[0] += center[0]\n",
    "                point[1] += center[1]\n",
    "                batch_data.append(point)\n",
    "                \n",
    "            batch_data = np.array(batch_data, dtype=np.float32)\n",
    "            batch_data /= 1.414  # std\n",
    "            yield batch_data\n",
    "            \n",
    "    elif dataset == '25gaussians':\n",
    "        batch_data = []\n",
    "        for i_ in range(4000):\n",
    "            for x in range(-2, 3):\n",
    "                for y in range(-2, 3):\n",
    "                    point = np.random.randn(2) * 0.05\n",
    "                    point[0] += 2*x\n",
    "                    point[1] += 2*y\n",
    "                    batch_data.append(point)\n",
    "                    \n",
    "        batch_data = np.asarray(batch_data, dtype=np.float32)\n",
    "        np.random.shuffle(batch_data)\n",
    "        batch_data /= 2.828  # std\n",
    "        \n",
    "        while True:\n",
    "            for i_ in range(int(len(batch_data)/BATCH_SIZE)):\n",
    "                yield batch_data[i_*BATCH_SIZE:(i_+1)*BATCH_SIZE]\n",
    "                \n",
    "    elif dataset == 'swissroll':\n",
    "        while True:\n",
    "            batch_data = sklearn.datasets.make_swiss_roll(n_samples=BATCH_SIZE, noise=0.25)[0]\n",
    "            batch_data = batch_data.astype(np.float32)[:, [0, 2]]\n",
    "            batch_data /= 7.5  # stdev plus a little\n",
    "            yield batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\n",
      "(60000, 100)\n",
      "One samples mean\n",
      "1.0179480513395647\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = 1, 0.3 # mean and standard deviation\n",
    "n_train_samples = 60000\n",
    "numero_especies = 100\n",
    "\n",
    "train_data = np.random.normal(mu, sigma, (n_train_samples,numero_especies))\n",
    "print(\"Shape\")\n",
    "print(train_data.shape)\n",
    "print(\"One samples mean\")\n",
    "print(np.mean(train_data[0,:]))\n",
    "\n",
    "my_ds = DataSetManager(train_data, norm=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> (iters: 0) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: -0.047194555\n",
      "==> STD: 0.28262785\n",
      "iter 0\tdisc cost\t-1.0242012739181519\n",
      "==> (iters: 250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.1943992\n",
      "==> STD: 0.32700753\n",
      "iter 250\tdisc cost\t-2.858675781607628\n",
      "==> (iters: 500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0017611\n",
      "==> STD: 0.26718587\n",
      "iter 500\tdisc cost\t-0.5118419626951217\n",
      "==> (iters: 750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0170488\n",
      "==> STD: 0.31715298\n",
      "iter 750\tdisc cost\t-0.4827130918502808\n",
      "==> (iters: 1000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0921504\n",
      "==> STD: 0.32728964\n",
      "iter 1000\tdisc cost\t-0.45126768630743025\n",
      "==> (iters: 1250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9186504\n",
      "==> STD: 0.29542434\n",
      "iter 1250\tdisc cost\t-0.42866129165887834\n",
      "==> (iters: 1500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9489261\n",
      "==> STD: 0.3093367\n",
      "iter 1500\tdisc cost\t-0.39426825284957884\n",
      "==> (iters: 1750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.8724422\n",
      "==> STD: 0.28007698\n",
      "iter 1750\tdisc cost\t-0.4177860976457596\n",
      "==> (iters: 2000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.8916193\n",
      "==> STD: 0.28626543\n",
      "iter 2000\tdisc cost\t-0.41317615884542463\n",
      "==> (iters: 2250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0222843\n",
      "==> STD: 0.28178385\n",
      "iter 2250\tdisc cost\t-0.4097370729446411\n",
      "==> (iters: 2500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.92527753\n",
      "==> STD: 0.296146\n",
      "iter 2500\tdisc cost\t-0.391006289601326\n",
      "==> (iters: 2750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.8317894\n",
      "==> STD: 0.24474531\n",
      "iter 2750\tdisc cost\t-0.3784663155823946\n",
      "==> (iters: 3000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9449341\n",
      "==> STD: 0.29719222\n",
      "iter 3000\tdisc cost\t-0.328385257601738\n",
      "==> (iters: 3250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.94571775\n",
      "==> STD: 0.26954007\n",
      "iter 3250\tdisc cost\t-0.34982450169324875\n",
      "==> (iters: 3500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.85521615\n",
      "==> STD: 0.24303614\n",
      "iter 3500\tdisc cost\t-0.2921135860234499\n",
      "==> (iters: 3750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0710247\n",
      "==> STD: 0.32260302\n",
      "iter 3750\tdisc cost\t-0.3166773212403059\n",
      "==> (iters: 4000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.97358185\n",
      "==> STD: 0.2612119\n",
      "iter 4000\tdisc cost\t-0.3268303583264351\n",
      "==> (iters: 4250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0406815\n",
      "==> STD: 0.30975494\n",
      "iter 4250\tdisc cost\t-0.30602659882605077\n",
      "==> (iters: 4500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.79618245\n",
      "==> STD: 0.2705719\n",
      "iter 4500\tdisc cost\t-0.32346117359399795\n",
      "==> (iters: 4750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9774788\n",
      "==> STD: 0.29402566\n",
      "iter 4750\tdisc cost\t-0.3021008643656969\n",
      "==> (iters: 5000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.93561137\n",
      "==> STD: 0.30588344\n",
      "iter 5000\tdisc cost\t-0.26227425357699397\n",
      "==> (iters: 5250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9253925\n",
      "==> STD: 0.26297647\n",
      "iter 5250\tdisc cost\t-0.30874371971935033\n",
      "==> (iters: 5500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.011036\n",
      "==> STD: 0.29868516\n",
      "iter 5500\tdisc cost\t-0.279094293653965\n",
      "==> (iters: 5750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9798083\n",
      "==> STD: 0.28679213\n",
      "iter 5750\tdisc cost\t-0.2722062742337584\n",
      "==> (iters: 6000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.97594285\n",
      "==> STD: 0.2720337\n",
      "iter 6000\tdisc cost\t-0.24092217779159547\n",
      "==> (iters: 6250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9531354\n",
      "==> STD: 0.3359316\n",
      "iter 6250\tdisc cost\t-0.28126242792606354\n",
      "==> (iters: 6500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9169289\n",
      "==> STD: 0.25159663\n",
      "iter 6500\tdisc cost\t-0.24888825259357691\n",
      "==> (iters: 6750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.1534005\n",
      "==> STD: 0.33738422\n",
      "iter 6750\tdisc cost\t-0.24659510880708693\n",
      "==> (iters: 7000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.2443317\n",
      "==> STD: 0.34175166\n",
      "iter 7000\tdisc cost\t-0.29505398687720297\n",
      "==> (iters: 7250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.8511265\n",
      "==> STD: 0.23211679\n",
      "iter 7250\tdisc cost\t-0.38754430556297303\n",
      "==> (iters: 7500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9293834\n",
      "==> STD: 0.2582428\n",
      "iter 7500\tdisc cost\t-0.4033364552259445\n",
      "==> (iters: 7750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9311407\n",
      "==> STD: 0.26982206\n",
      "iter 7750\tdisc cost\t-0.3876907345056534\n",
      "==> (iters: 8000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.97858787\n",
      "==> STD: 0.30811408\n",
      "iter 8000\tdisc cost\t-0.37924351525306704\n",
      "==> (iters: 8250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.89401925\n",
      "==> STD: 0.26446834\n",
      "iter 8250\tdisc cost\t-0.3745644910335541\n",
      "==> (iters: 8500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0081731\n",
      "==> STD: 0.2954004\n",
      "iter 8500\tdisc cost\t-0.35244088995456696\n",
      "==> (iters: 8750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9775747\n",
      "==> STD: 0.26701432\n",
      "iter 8750\tdisc cost\t-0.3486159384846687\n",
      "==> (iters: 9000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.97423136\n",
      "==> STD: 0.27754885\n",
      "iter 9000\tdisc cost\t-0.3405220177769661\n",
      "==> (iters: 9250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0218077\n",
      "==> STD: 0.30115893\n",
      "iter 9250\tdisc cost\t-0.33043525385856626\n",
      "==> (iters: 9500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9052017\n",
      "==> STD: 0.26299137\n",
      "iter 9500\tdisc cost\t-0.31641091030836105\n",
      "==> (iters: 9750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.95536804\n",
      "==> STD: 0.26019782\n",
      "iter 9750\tdisc cost\t-0.30891607868671417\n",
      "==> (iters: 10000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.923905\n",
      "==> STD: 0.28315613\n",
      "iter 10000\tdisc cost\t-0.30732818228006364\n",
      "==> (iters: 10250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0362855\n",
      "==> STD: 0.31396154\n",
      "iter 10250\tdisc cost\t-0.2910826611816883\n",
      "==> (iters: 10500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0485559\n",
      "==> STD: 0.35295704\n",
      "iter 10500\tdisc cost\t-0.2848826909065247\n",
      "==> (iters: 10750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.89456505\n",
      "==> STD: 0.23579577\n",
      "iter 10750\tdisc cost\t-0.2767996923327446\n",
      "==> (iters: 11000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9877314\n",
      "==> STD: 0.28621072\n",
      "iter 11000\tdisc cost\t-0.27049750512838366\n",
      "==> (iters: 11250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0814235\n",
      "==> STD: 0.31873035\n",
      "iter 11250\tdisc cost\t-0.25097041052579877\n",
      "==> (iters: 11500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0197389\n",
      "==> STD: 0.29148197\n",
      "iter 11500\tdisc cost\t-0.2504709150493145\n",
      "==> (iters: 11750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0414861\n",
      "==> STD: 0.30489177\n",
      "iter 11750\tdisc cost\t-0.24444109505414963\n",
      "==> (iters: 12000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0405678\n",
      "==> STD: 0.288042\n",
      "iter 12000\tdisc cost\t-0.23183705832064153\n",
      "==> (iters: 12250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0045547\n",
      "==> STD: 0.28874612\n",
      "iter 12250\tdisc cost\t-0.23915178734064102\n",
      "==> (iters: 12500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.99110603\n",
      "==> STD: 0.28779048\n",
      "iter 12500\tdisc cost\t-0.2376057482659817\n",
      "==> (iters: 12750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9905325\n",
      "==> STD: 0.2992371\n",
      "iter 12750\tdisc cost\t-0.21536776596307755\n",
      "==> (iters: 13000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.1013381\n",
      "==> STD: 0.36947685\n",
      "iter 13000\tdisc cost\t-0.21258409491181374\n",
      "==> (iters: 13250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0508193\n",
      "==> STD: 0.30253235\n",
      "iter 13250\tdisc cost\t-0.20973097908496857\n",
      "==> (iters: 13500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.1233029\n",
      "==> STD: 0.3317311\n",
      "iter 13500\tdisc cost\t-0.20490726426243783\n",
      "==> (iters: 13750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.042943\n",
      "==> STD: 0.39331234\n",
      "iter 13750\tdisc cost\t-0.20336992898583411\n",
      "==> (iters: 14000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.005645\n",
      "==> STD: 0.30502355\n",
      "iter 14000\tdisc cost\t-0.19691900384426117\n",
      "==> (iters: 14250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.98557794\n",
      "==> STD: 0.34920022\n",
      "iter 14250\tdisc cost\t-0.19302060198783874\n",
      "==> (iters: 14500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0711703\n",
      "==> STD: 0.3546101\n",
      "iter 14500\tdisc cost\t-0.19478367561101914\n",
      "==> (iters: 14750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0182942\n",
      "==> STD: 0.33660707\n",
      "iter 14750\tdisc cost\t-0.18198907002806664\n",
      "==> (iters: 15000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0253937\n",
      "==> STD: 0.30342567\n",
      "iter 15000\tdisc cost\t-0.17578616137057543\n",
      "==> (iters: 15250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9772932\n",
      "==> STD: 0.30160075\n",
      "iter 15250\tdisc cost\t-0.1773105691075325\n",
      "==> (iters: 15500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.937973\n",
      "==> STD: 0.25308463\n",
      "iter 15500\tdisc cost\t-0.16717538755387068\n",
      "==> (iters: 15750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0412999\n",
      "==> STD: 0.2938786\n",
      "iter 15750\tdisc cost\t-0.17117161764204503\n",
      "==> (iters: 16000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0324584\n",
      "==> STD: 0.2358757\n",
      "iter 16000\tdisc cost\t-0.16675566060096025\n",
      "==> (iters: 16250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0241553\n",
      "==> STD: 0.3046371\n",
      "iter 16250\tdisc cost\t-0.16811472225189208\n",
      "==> (iters: 16500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0069085\n",
      "==> STD: 0.3535592\n",
      "iter 16500\tdisc cost\t-0.16466981241852044\n",
      "==> (iters: 16750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0127643\n",
      "==> STD: 0.2844812\n",
      "iter 16750\tdisc cost\t-0.14026649252325296\n",
      "==> (iters: 17000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9833824\n",
      "==> STD: 0.26402318\n",
      "iter 17000\tdisc cost\t-0.14951687897741794\n",
      "==> (iters: 17250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0284119\n",
      "==> STD: 0.28585884\n",
      "iter 17250\tdisc cost\t-0.13208764561265707\n",
      "==> (iters: 17500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9920037\n",
      "==> STD: 0.2721138\n",
      "iter 17500\tdisc cost\t-0.14257368541508914\n",
      "==> (iters: 17750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.95506406\n",
      "==> STD: 0.32211325\n",
      "iter 17750\tdisc cost\t-0.12728930676728487\n",
      "==> (iters: 18000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.017546\n",
      "==> STD: 0.35697865\n",
      "iter 18000\tdisc cost\t-0.12934168534725904\n",
      "==> (iters: 18250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.91213816\n",
      "==> STD: 0.21626745\n",
      "iter 18250\tdisc cost\t-0.14033672642707826\n",
      "==> (iters: 18500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9972836\n",
      "==> STD: 0.29223418\n",
      "iter 18500\tdisc cost\t-0.13677038718760012\n",
      "==> (iters: 18750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0121797\n",
      "==> STD: 0.27893892\n",
      "iter 18750\tdisc cost\t-0.12644026533141733\n",
      "==> (iters: 19000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9974336\n",
      "==> STD: 0.2841484\n",
      "iter 19000\tdisc cost\t-0.12492043982446194\n",
      "==> (iters: 19250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.92790735\n",
      "==> STD: 0.27989677\n",
      "iter 19250\tdisc cost\t-0.13740668737888337\n",
      "==> (iters: 19500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.99849474\n",
      "==> STD: 0.344418\n",
      "iter 19500\tdisc cost\t-0.11737152035534382\n",
      "==> (iters: 19750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.97308916\n",
      "==> STD: 0.26819485\n",
      "iter 19750\tdisc cost\t-0.11487911437451839\n",
      "==> (iters: 20000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.045811\n",
      "==> STD: 0.32815242\n",
      "iter 20000\tdisc cost\t-0.11563339073210954\n",
      "==> (iters: 20250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9875026\n",
      "==> STD: 0.28048602\n",
      "iter 20250\tdisc cost\t-0.10813696908205747\n",
      "==> (iters: 20500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9746162\n",
      "==> STD: 0.29075176\n",
      "iter 20500\tdisc cost\t-0.1050387694016099\n",
      "==> (iters: 20750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0433007\n",
      "==> STD: 0.29590282\n",
      "iter 20750\tdisc cost\t-0.10626329914480448\n",
      "==> (iters: 21000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.95845467\n",
      "==> STD: 0.30417565\n",
      "iter 21000\tdisc cost\t-0.10187552397698164\n",
      "==> (iters: 21250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 1.0337478\n",
      "==> STD: 0.2469973\n",
      "iter 21250\tdisc cost\t-0.11463135581463575\n",
      "==> (iters: 21500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.96254385\n",
      "==> STD: 0.30653602\n",
      "iter 21500\tdisc cost\t-0.12423179488629103\n",
      "==> (iters: 21750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9722562\n",
      "==> STD: 0.2481191\n",
      "iter 21750\tdisc cost\t-0.11205564063042402\n",
      "==> (iters: 22000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9888677\n",
      "==> STD: 0.31828165\n",
      "iter 22000\tdisc cost\t-0.10656574056297541\n",
      "==> (iters: 22250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.9790047\n",
      "==> STD: 0.28342494\n",
      "iter 22250\tdisc cost\t-0.09864445388689637\n",
      "==> (iters: 22500) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.94780004\n",
      "==> STD: 0.27870706\n",
      "iter 22500\tdisc cost\t-0.10590779762342573\n",
      "==> (iters: 22750) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.98013335\n",
      "==> STD: 0.27698788\n",
      "iter 22750\tdisc cost\t-0.09629542260617018\n",
      "==> (iters: 23000) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.92145365\n",
      "==> STD: 0.23584387\n",
      "iter 23000\tdisc cost\t-0.10117167584970593\n",
      "==> (iters: 23250) Fake Samples Summary; mu 1; sigma 0.3 <===\n",
      "==> Shape: (100,)\n",
      "==> Mean: 0.98403823\n",
      "==> STD: 0.3176135\n",
      "iter 23250\tdisc cost\t-0.10392746890336275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4103e06d7607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCRITIC_ITERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmy_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# data_gen.__next__()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdisc_cost_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdisc_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_train_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'wgan'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Train loop\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    data_gen = inf_train_gen()\n",
    "    \n",
    "    for iter_ in range(ITERS):\n",
    "        batch_data, disc_cost_ = None, None\n",
    "        \n",
    "        # train critic\n",
    "        for i_ in range(CRITIC_ITERS):\n",
    "            batch_data =  my_ds.next_batch(BATCH_SIZE) # data_gen.__next__()\n",
    "            disc_cost_, _ = sess.run([disc_cost, disc_train_op], feed_dict={real_data: batch_data})\n",
    "            \n",
    "            if mode == 'wgan':\n",
    "                sess.run(clip_disc_weights)\n",
    "        \n",
    "        # train generator\n",
    "        sess.run(gen_train_op)\n",
    "        \n",
    "        # write logs and svae samples\n",
    "        utils.plot('disc cost', disc_cost_)\n",
    "        \n",
    "        if (np.mod(iter_, FREQ) == 0) or (iter_+1 == ITERS):\n",
    "            \n",
    "            fake_samples = sess.run(fake_data, feed_dict={real_data: batch_data})\n",
    "            \n",
    "            fake_samples = fake_samples[0,:]\n",
    "            print(\"==> (iters: \"+str(iter_)+\") Fake Samples Summary; mu \"+str(mu)+\"; sigma \"+str(sigma)+\" <===\")\n",
    "            a1 = str(fake_samples.shape)\n",
    "            print(\"==> Shape: \"+a1)\n",
    "            \n",
    "            a2 = str(np.mean(fake_samples))\n",
    "            print(\"==> Mean: \"+a2)\n",
    "            \n",
    "            a3 = str(np.std(fake_samples))\n",
    "            print(\"==> STD: \"+a3)\n",
    "            utils.flush(img_folder)\n",
    "            # generate_image(sess, batch_data, iter_)\n",
    "            \n",
    "        utils.tick()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(fake_samples -1 < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3176135"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(fake_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
