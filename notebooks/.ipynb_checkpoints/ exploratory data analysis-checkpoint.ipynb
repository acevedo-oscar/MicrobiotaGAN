{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gan_samples =  pd.read_csv('../data/dirichlet_gan_samples.csv',header=None  ).values # \n",
    "new_training_samples =  pd.read_csv('../data/dirichlet_100spec.csv',header=None  ).values # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylo_ds =  pd.read_csv('../data/phylogeny_data/simulated_otu_table_clean.csv',header=None  ).values # \n",
    "\n",
    "gan_ds =  pd.read_csv('../data/phylogeny_data/phylo_gan_samples.csv',header=None  ).values # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(phylo_ds[6,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Norm of mean and STD vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std_vec = np.std(phylo_ds, axis=0 )#each element represent one column\n",
    "\n",
    "gan_std_vec = np.std(gan_ds, axis=0)\n",
    "\n",
    "\n",
    "print(\"\\nL2 Train std\")\n",
    "print(np.linalg.norm(train_std_vec, ord=2))\n",
    "\n",
    "print(\"\\nL2 GAN std\")\n",
    "print(np.linalg.norm(gan_std_vec, ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_vec = np.mean(phylo_ds, axis=0 )#each element represent one column\n",
    "\n",
    " \n",
    "gan_mean_vec = np.mean(gan_ds, axis=0)\n",
    "\n",
    "\n",
    "print(\"\\nL2 Train mean\")\n",
    "print(np.linalg.norm(train_mean_vec, ord=2))\n",
    "\n",
    "print(\"\\nL2 GAN mean\")\n",
    "print(np.linalg.norm(gan_mean_vec, ord=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting elements greater than $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train = copy.copy(phylo_ds)\n",
    "\n",
    "alt_train[alt_train==0] = 3\n",
    "\n",
    "alt_gan = copy.copy(gan_ds)\n",
    "\n",
    "alt_gan[alt_gan==0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_epsilon(data, epsilon):\n",
    "    print(\"Shape: \"+str(data.shape))\n",
    "\n",
    "    train_greater = np.sum(data > epsilon, axis = 0)\n",
    "\n",
    "    print(\"\\n Number of elements greater than epsilon\")\n",
    "    # print(train_greater)\n",
    "    a1 = np.sum(train_greater)\n",
    "    print(a1)\n",
    "\n",
    "    percent = 100*(a1/(alt_train.shape[1]*alt_train.shape[0]))\n",
    "    print(\"As % of data: \"+str(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon =  10e-7\n",
    "print(\"Nota: Los ceros fueron parchados\")\n",
    "print(\"Epsilon: \"+str(epsilon))\n",
    "print(\"\\n\")\n",
    "\n",
    "summarize_epsilon(alt_train, epsilon)\n",
    "\n",
    "summarize_epsilon(alt_gan, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples\n",
    "\n",
    "summarize_epsilon(new_samples, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_samples.shape)\n",
    "\n",
    "s1 = new_samples[0,:]\n",
    "print(s1)\n",
    "np.sum(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gan = copy.copy(new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(c_gan > 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Some Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "k = np.random.randint(new_gan_samples.shape[0])\n",
    "print(k)\n",
    "sub_data = new_training_samples[k,:]\n",
    "sub_gan = new_gan_samples[k,:]\n",
    "print(sub_data.shape)\n",
    "sns.distplot(sub_data,bins=20, kde=False)\n",
    "sns.distplot(sub_gan,bins=20, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_of_samples = np.sum(new_training_samples, axis=0) #//new_training_samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = average_of_samples/ np.linalg.norm(average_of_samples, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(average_of_samples**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(normalized, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "K = np.ones(100) # This was the alpha vector used to generate the data\n",
    "\n",
    "norm_c = np.linalg.norm(K, ord=2)\n",
    "norm_k = K/norm_c\n",
    "print(norm_k)\n",
    "print(norm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have to test if data is on the simplex described by the above numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1= new_training_samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dir(point ):   \n",
    "    return np.sum(point, axis=0)/point.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0099875 , 0.01003651, 0.01005461, 0.00997314, 0.00998334,\n",
       "       0.00994712, 0.00996554, 0.01000543, 0.00993231, 0.00995206,\n",
       "       0.01001143, 0.00998412, 0.01001896, 0.00999984, 0.00998962,\n",
       "       0.00997912, 0.01007215, 0.01000925, 0.01003189, 0.01002811,\n",
       "       0.00996221, 0.00992988, 0.01005335, 0.01003878, 0.00998893,\n",
       "       0.01000134, 0.01001897, 0.0100137 , 0.01009487, 0.01006854,\n",
       "       0.01000817, 0.01001273, 0.01008953, 0.01005597, 0.009919  ,\n",
       "       0.01002267, 0.00993101, 0.00999787, 0.01008484, 0.00998836,\n",
       "       0.01001259, 0.0099418 , 0.01002017, 0.01000241, 0.00995607,\n",
       "       0.00997489, 0.01003136, 0.00996973, 0.01002616, 0.01000619,\n",
       "       0.00999748, 0.01001442, 0.00996861, 0.0100293 , 0.01003508,\n",
       "       0.01001499, 0.01005327, 0.00994187, 0.00995411, 0.01000185,\n",
       "       0.00996092, 0.01001032, 0.0099979 , 0.01001819, 0.01005453,\n",
       "       0.00999876, 0.0099688 , 0.00997128, 0.01006555, 0.0100433 ,\n",
       "       0.01000842, 0.01004547, 0.00999212, 0.00999569, 0.00999037,\n",
       "       0.01001048, 0.00997159, 0.00995841, 0.01001847, 0.00994431,\n",
       "       0.00993359, 0.00998814, 0.0100254 , 0.01001652, 0.00992505,\n",
       "       0.00993957, 0.01002752, 0.01002235, 0.00997444, 0.01004858,\n",
       "       0.00989277, 0.00995714, 0.01005671, 0.00994051, 0.01003763,\n",
       "       0.00998278, 0.00998413, 0.01002722, 0.01001286, 0.00998708])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(new_training_samples, axis=0)/new_training_samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01006562, 0.01060201, 0.00939326, 0.01066261, 0.00839568,\n",
       "       0.00867846, 0.00986383, 0.00892806, 0.00922239, 0.01042323,\n",
       "       0.01241126, 0.00885244, 0.01135979, 0.01007721, 0.00952929,\n",
       "       0.01038234, 0.00929688, 0.01146677, 0.01178913, 0.00889552,\n",
       "       0.01077789, 0.01066141, 0.01132662, 0.01254065, 0.00970659,\n",
       "       0.00947724, 0.0093698 , 0.00739294, 0.00969986, 0.01285481,\n",
       "       0.00937918, 0.01069378, 0.00932177, 0.00928982, 0.01018118,\n",
       "       0.01037383, 0.00944713, 0.01054213, 0.01063923, 0.0090338 ,\n",
       "       0.01074361, 0.01037796, 0.01035835, 0.01001522, 0.00980194,\n",
       "       0.00775463, 0.01167995, 0.00846307, 0.01153496, 0.00901075,\n",
       "       0.00991259, 0.01049729, 0.01096462, 0.00910769, 0.01185234,\n",
       "       0.0101241 , 0.01097751, 0.00877353, 0.00893083, 0.0099851 ,\n",
       "       0.00880109, 0.01061159, 0.01036288, 0.01144762, 0.00914435,\n",
       "       0.00994262, 0.01064267, 0.0103603 , 0.00698218, 0.00967797,\n",
       "       0.00836856, 0.00885994, 0.01232335, 0.01006076, 0.00939223,\n",
       "       0.01152035, 0.00978426, 0.01046862, 0.00807506, 0.01051234,\n",
       "       0.00943158, 0.00994022, 0.01004638, 0.0106313 , 0.0092881 ,\n",
       "       0.01110692, 0.0112986 , 0.010334  , 0.01008421, 0.01216635,\n",
       "       0.00961286, 0.0084606 , 0.01049413, 0.00908176, 0.0090381 ,\n",
       "       0.00817612, 0.00788623, 0.01160228, 0.01026825, 0.0098418 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(new_gan_samples, axis=0)/new_gan_samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
