{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acevedo/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import copy \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(data, n:float, seed=0):\n",
    "    dummy_labels = np.ones(data.shape[0])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, dummy_labels, test_size=n, random_state=seed)\n",
    "    return [X_train, X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../data/DS_1.csv', header=None) .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data = pd.read_csv('../data/gan_dirichlet_1.csv', header=None) .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_dataset(my_data, n=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22827\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(my_data ==0))\n",
    "print(np.sum(gan_data ==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error de Validacion\n",
    "\n",
    "En esta parte hay que definir un error para nuestra GAN.\n",
    "\n",
    "## Clasificacion \n",
    "+ Para problemas de **clasificacion** una medida del error puede ser **clasificaciones correctas/numero total de clasificacones**\n",
    "+ Para problemas de clasificacion multi clase existe una perdida logaritmica definida como: $$\\frac{-1}{N} \\mathop{\\sum_{i=1}^{N}\\sum_{j=1}^{M}} y_{ij}*log(p_{ij})$$\n",
    "\n",
    "Donde:\n",
    "+ $y_{ij}$ indica si la muestra i pertenece a la clase j\n",
    "+ $p_{ij}$  es la probabiliad de que la muestra i pertenezca a la calse j \n",
    "\n",
    "+ **F1 Score** : $$2 \\times \\frac{1}{ \\frac{1}{precision} + \\frac{1}{recall}}$$. Precision y recall se definen en terminos de TruePositives, FalsePositives y FalseNegatives\n",
    "\n",
    "## Regresion\n",
    "\n",
    "+ Mean Absolute Error\n",
    "+ Mean Squared Error\n",
    "\n",
    "## Medidas para las GANS\n",
    "\n",
    "En el caso de las GANs, la funcion objetivo o de perdida mide que tan bien el generador enga√±a al discriminador. Entonces, esta no nos dice mucho acerca de que tan reaslaticas o diversas son las muestras generadas por la GAN.\n",
    "\n",
    "Para el caso de **GAN de imagenes**, hay dos medidas del rendimiento de una gan, el Inception Score y el Frechet Inception Distance. (https://medium.com/@jonathan_hui/gan-how-to-measure-gan-performance-64b988c47732)\n",
    "\n",
    "**Una buena GAN es una que genera muestras diversas y realistas**. En el caso de las imagenes, no es trivial hacer que una computadora te diga que tan realistas es una imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapted Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/acevedo/Desktop/Current_GAN/MicrobiotaGAN/notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import scipy\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy import inf\n",
    "from copy import copy \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from get_disc_score import get_disc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path =  \"../model/dir1/my_gan.ckpt\"\n",
    "\n",
    "def pseudo_is_score(data, restore_path):\n",
    "    x = get_disc_score(val, restore_path )\n",
    "    \n",
    "    logits = np.exp(x)\n",
    "    \n",
    "    py = np.mean(logits, keepdims = True)\n",
    "    \n",
    "    # pxy_k = logits[k,:]\n",
    "    \n",
    "    print(py.shape)\n",
    "    print( logits.shape)\n",
    "    \n",
    "    assert py.shape[1] == logits.shape[1]\n",
    "    \n",
    "    N = data.shape[0]\n",
    "    \n",
    "    #pre_score = [DKL( logits[k,:], py ) for k in range(N) ]\n",
    "    \n",
    "    #pre_score = np.array(pre_score)\n",
    "    return py, logits\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = my_data[1:5,:] #.reshape(1,100)\n",
    "\n",
    "py, logits = pseudo_is_score(val, model_path)\n",
    "py = py.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = logits[0,:]\n",
    "\n",
    "b = py\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "DKL(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly use DKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DKL(pk_, qk_, epsilon = 0.01):\n",
    "    \n",
    "    \"\"\"   \n",
    "    n = pk.shape[0]    \n",
    "    normed_pk = normalize(pk.reshape(1,n),  norm='l1')\n",
    "    normed_qk = normalize(qk.reshape(1,n), norm='l1')\n",
    "    print(normed_pk)  \n",
    "    \"\"\"\n",
    "    pk = copy(pk_)\n",
    "    qk = copy(qk_)\n",
    "    \n",
    "    #print(pk.shape)\n",
    "    a = np.sum(pk ==0)\n",
    "    b = np.sum(qk ==0)\n",
    "    # assert a ==0 and b ==0\n",
    "    \n",
    "    #if  a !=0 or b !=0:\n",
    "        #print(\"Padding Zeroes\")\n",
    "\n",
    "    # Beware  zeros\n",
    "    pk[pk==0] = epsilon\n",
    "    qk[qk==0] = epsilon\n",
    "    \n",
    "    return scipy.stats.entropy(pk,qk)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 100)\n",
      "(10496, 100)\n"
     ]
    }
   ],
   "source": [
    "print(my_data.shape)\n",
    "print(gan_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37564066e-02, 9.45144306e-03, 1.18753532e-02, 5.51016020e-03,\n",
       "       6.32998650e-03, 2.29990033e-03, 5.01250543e-10, 1.44459718e-02,\n",
       "       1.36204768e-02, 1.54375615e-02, 1.56328553e-02, 7.22922077e-03,\n",
       "       1.41422534e-02, 8.70603553e-03, 9.95337207e-03, 1.58851705e-02,\n",
       "       2.02201848e-03, 6.98321249e-03, 5.67383269e-03, 2.28466485e-03,\n",
       "       2.03128772e-02, 1.89572380e-02, 9.83402864e-04, 1.73718766e-02,\n",
       "       5.35791553e-03, 2.09320964e-02, 1.18684752e-02, 1.37521632e-03,\n",
       "       2.44065156e-02, 2.43678712e-03, 7.95542054e-03, 9.80936596e-03,\n",
       "       7.08557422e-03, 1.52093626e-02, 1.98437389e-10, 1.89933099e-02,\n",
       "       1.71708419e-02, 1.28917908e-02, 1.59609811e-02, 8.26280798e-10,\n",
       "       3.48731532e-03, 1.30329955e-02, 9.42632352e-03, 1.63433780e-02,\n",
       "       1.10884379e-02, 2.67281439e-03, 7.31037685e-03, 1.27048243e-10,\n",
       "       7.99585306e-03, 1.43714767e-02, 1.86479217e-02, 6.59152310e-03,\n",
       "       1.99920297e-02, 9.57546500e-03, 1.42470927e-03, 1.81391723e-02,\n",
       "       1.82865450e-03, 1.54360909e-02, 4.73223649e-03, 8.46560100e-03,\n",
       "       1.24814518e-09, 1.07529567e-02, 1.85569146e-03, 3.19537424e-03,\n",
       "       3.22803660e-10, 1.31021774e-02, 7.72056163e-03, 1.13877682e-02,\n",
       "       1.57494158e-02, 1.30916662e-03, 7.04472674e-10, 1.38006746e-03,\n",
       "       8.17412761e-03, 1.19697295e-02, 6.52374583e-03, 1.16211541e-02,\n",
       "       1.91619102e-02, 1.01532158e-10, 5.96544431e-03, 1.82090531e-02,\n",
       "       2.32658566e-02, 1.39844836e-02, 1.83481966e-02, 1.90096667e-02,\n",
       "       1.55503425e-02, 1.51648273e-02, 1.13546950e-02, 1.88040802e-02,\n",
       "       1.19511457e-02, 1.72832373e-03, 8.41909421e-03, 2.47411424e-02,\n",
       "       2.72748279e-03, 1.27465565e-03, 7.10901326e-04, 2.48169588e-03,\n",
       "       6.21170500e-03, 1.91461473e-02, 1.66691284e-02, 1.94967621e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.014635214980626745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n =10000\n",
    "a = gan_data[0:n,:].mean(axis=0)\n",
    "b = my_data [0:n,:].mean(axis=0)\n",
    "\n",
    "print(np.sum(a ==0))\n",
    "print(np.sum(b ==0))\n",
    "\n",
    "DKL(b,a) == DKL(b,a)\n",
    "\n",
    "DKL(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3775\n"
     ]
    }
   ],
   "source": [
    "a = gan_data[0:n,:]\n",
    "b = my_data [0:n,:]\n",
    "\n",
    "print(np.sum(a ==0))\n",
    "print(np.sum(b ==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = [DKL(a[k,:], b[k,:]) for k in range(n)]\n",
    "entropy = np.array(entropy)\n",
    "np.sum(entropy== inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000063142494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7026625892132428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "#print(a[k,:])\n",
    "#print(b[k,:])\n",
    "#print(scipy.spatial.distance.euclidean(a[k,:], b[k,:]))\n",
    "\n",
    "print(a[k,:].sum())\n",
    "DKL(a[k,:], b[k,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#entropy[entropy == inf] = 0\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "\n",
    "for k in range(10000):\n",
    "    if entropy[k] == inf:\n",
    "        index_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = index_list[20]\n",
    "\n",
    "\n",
    "DKL(a[k,:], b[k,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4286138610097665\n",
      "0.5615696872767789\n",
      "0.5534138845744595\n",
      "0.5420345698934665\n",
      "0.5102815653968453\n",
      "0.5598169817407366\n",
      "0.5036637162188121\n",
      "0.49263605804010524\n",
      "0.48464844191133655\n",
      "0.4547260827055967\n",
      "0.49869510742390516\n",
      "0.53078418504643\n",
      "0.5207210746436747\n",
      "0.5413437235250858\n",
      "0.4509219856064896\n",
      "0.5104140388145447\n",
      "0.5073363773535575\n",
      "0.5453110613288602\n",
      "0.5460892897204823\n",
      "0.510973972418934\n",
      "0.49525423810035907\n",
      "0.5479579460130466\n",
      "0.4904343880292508\n",
      "0.4772198829705362\n",
      "0.5990379035607402\n",
      "0.5387733329982543\n",
      "0.5803750391294598\n",
      "0.4560665143873316\n",
      "0.4999172230621607\n",
      "0.583097717848842\n",
      "0.44149019713495735\n",
      "0.5779679358466613\n",
      "0.4373269350769362\n",
      "0.5420048509456248\n",
      "0.541009081550116\n",
      "0.5817857386177405\n",
      "0.5141111741765869\n",
      "0.5484392649002604\n",
      "0.4840330185482366\n",
      "0.5139837969671777\n",
      "0.4435496446351288\n",
      "0.4936907651492526\n",
      "0.4764272782871642\n"
     ]
    }
   ],
   "source": [
    "for e in range(len(index_list)):\n",
    "    k = index_list[e]\n",
    "    print(distance.jensenshannon(a[k,:], b[k,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 87\n",
    "\n",
    "print(a[k,:].std())\n",
    "print(b[k,:].std())\n",
    "print(a[k,:].sum())\n",
    "\n",
    "DKL(a[k,:], b[k,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = distance.jensenshannon(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "entropy2 = [distance.jensenshannon(a[k,:], b[k,:]) for k in range(n)]\n",
    "entropy = np.array(entropy)\n",
    "np.sum(entropy== inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
