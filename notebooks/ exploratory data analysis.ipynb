{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
<<<<<<< HEAD
    "import matplotlib.pyplot as plt\n",
=======
    "import matplotlib as plt\n",
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "new_gan_samples =  pd.read_csv('../data/k1_dirichlet_gan_samples.csv',header=None  ).values # \n",
    "new_training_samples =  pd.read_csv('../data/k1_dirichlet_100spec.csv',header=None  ).values # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
    "phylo_ds =  pd.read_csv('../data/phylogeny_data/simulated_otu_table_clean.csv',header=None  ).values # \n",
    "\n",
    "gan_ds =  pd.read_csv('../data/phylogeny_data/phylo_gan_samples.csv',header=None  ).values # "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 6,
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
<<<<<<< HEAD
     "execution_count": 4,
=======
     "execution_count": 6,
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(phylo_ds[6,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Norm of mean and STD vectors"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Train std\n",
      "0.4791372562983442\n",
      "\n",
      "L2 GAN std\n",
      "0.4702367447845163\n"
     ]
    }
   ],
   "source": [
    "train_std_vec = np.std(phylo_ds, axis=0 )#each element represent one column\n",
    "\n",
    "gan_std_vec = np.std(gan_ds, axis=0)\n",
    "\n",
    "\n",
    "print(\"\\nL2 Train std\")\n",
    "print(np.linalg.norm(train_std_vec, ord=2))\n",
    "\n",
    "print(\"\\nL2 GAN std\")\n",
    "print(np.linalg.norm(gan_std_vec, ord=2))\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Train mean\n",
      "0.12694195081183723\n",
      "\n",
      "L2 GAN mean\n",
      "0.12858382242165867\n"
     ]
    }
   ],
   "source": [
    "train_mean_vec = np.mean(phylo_ds, axis=0 )#each element represent one column\n",
    "\n",
    " \n",
    "gan_mean_vec = np.mean(gan_ds, axis=0)\n",
    "\n",
    "\n",
    "print(\"\\nL2 Train mean\")\n",
    "print(np.linalg.norm(train_mean_vec, ord=2))\n",
    "\n",
    "print(\"\\nL2 GAN mean\")\n",
    "print(np.linalg.norm(gan_mean_vec, ord=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting elements greater than $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 5,
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train = copy.copy(phylo_ds)\n",
    "\n",
    "alt_train[alt_train==0] = 3\n",
    "\n",
    "alt_gan = copy.copy(gan_ds)\n",
    "\n",
    "alt_gan[alt_gan==0] = 3"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_epsilon(data, epsilon):\n",
    "    print(\"Shape: \"+str(data.shape))\n",
    "\n",
    "    train_greater = np.sum(data > epsilon, axis = 0)\n",
    "\n",
    "    print(\"\\n Number of elements greater than epsilon\")\n",
    "    # print(train_greater)\n",
    "    a1 = np.sum(train_greater)\n",
    "    print(a1)\n",
    "\n",
    "    percent = 100*(a1/(alt_train.shape[1]*alt_train.shape[0]))\n",
    "    print(\"As % of data: \"+str(percent))"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.min(alt_train, axis=0)[0:10])\n",
    "# print(np.min(alt_gan, axis=0)[0:10])"
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 38,
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Nota: Los ceros fueron parchados\n",
      "Epsilon: 1e-06\n",
      "\n",
      "\n",
      "Shape: (100000, 128)\n",
      "\n",
      " Number of elements greater than epsilon\n",
      "12798009\n",
      "As % of data: 99.9844453125\n",
      "Shape: (100352, 128)\n",
      "\n",
      " Number of elements greater than epsilon\n",
      "8968258\n",
      "As % of data: 70.064515625\n"
=======
      "(100000, 128)\n",
      "Nota: Los ceros fueron parchados\n",
      "Epsilon: 1e-06\n",
      "\n",
      "Train\n",
      "12798009\n",
      "As % of data: 99.9844453125\n",
      "\n",
      "GAN\n",
      "8968258\n",
      "As % of data: 69.81875361228475\n"
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "epsilon =  10e-7\n",
    "print(\"Nota: Los ceros fueron parchados\")\n",
    "print(\"Epsilon: \"+str(epsilon))\n",
    "print(\"\\n\")\n",
    "\n",
    "summarize_epsilon(alt_train, epsilon)\n",
    "\n",
    "summarize_epsilon(alt_gan, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5c14b4059b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msummarize_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_samples' is not defined"
     ]
    }
   ],
   "source": [
    "new_samples\n",
    "\n",
    "summarize_epsilon(new_samples, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_samples.shape)\n",
    "\n",
    "s1 = new_samples[0,:]\n",
    "print(s1)\n",
    "np.sum(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_gan = copy.copy(new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(c_gan > 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Some Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_of_samples = np.sum(new_training_samples, axis=0) #//new_training_samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = average_of_samples/ np.linalg.norm(average_of_samples, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(average_of_samples**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(normalized, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "K = np.ones(100) # This was the alpha vector used to generate the data\n",
    "\n",
    "norm_c = np.linalg.norm(K, ord=1)\n",
    "norm_k_vec = K/norm_c\n",
    "print(norm_k_vec)\n",
    "print(norm_c)\n",
    " "
=======
    "print(alt_train.shape)\n",
    "epsilon =  10e-7\n",
    "print(\"Nota: Los ceros fueron parchados\")\n",
    "print(\"Epsilon: \"+str(epsilon))\n",
    "\n",
    "train_greater = np.sum(alt_train > epsilon, axis = 0)\n",
    "\n",
    "print(\"\\nTrain\")\n",
    "# print(train_greater)\n",
    "a1 = np.sum(train_greater)\n",
    "print(a1)\n",
    "\n",
    "percent = 100*(a1/(128*alt_train.shape[0]))\n",
    "print(\"As % of data: \"+str(percent))\n",
    "\n",
    "gan_greater = np.sum(alt_gan > epsilon, axis = 0)\n",
    "print(\"\\nGAN\")\n",
    "# print(gan_greater)\n",
    "\n",
    "a2 = np.sum(gan_greater)\n",
    "print(a2)\n",
    "\n",
    "percent2 = 100*(a2/(128*alt_gan.shape[0]))\n",
    "print(\"As % of data: \"+str(percent2))"
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have to test if data is on the simplex described by the above numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1= new_training_samples[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0099875 , 0.01003651, 0.01005461, 0.00997314, 0.00998334,\n",
       "       0.00994712, 0.00996554, 0.01000543, 0.00993231, 0.00995206,\n",
       "       0.01001143, 0.00998412, 0.01001896, 0.00999984, 0.00998962,\n",
       "       0.00997912, 0.01007215, 0.01000925, 0.01003189, 0.01002811,\n",
       "       0.00996221, 0.00992988, 0.01005335, 0.01003878, 0.00998893,\n",
       "       0.01000134, 0.01001897, 0.0100137 , 0.01009487, 0.01006854,\n",
       "       0.01000817, 0.01001273, 0.01008953, 0.01005597, 0.009919  ,\n",
       "       0.01002267, 0.00993101, 0.00999787, 0.01008484, 0.00998836,\n",
       "       0.01001259, 0.0099418 , 0.01002017, 0.01000241, 0.00995607,\n",
       "       0.00997489, 0.01003136, 0.00996973, 0.01002616, 0.01000619,\n",
       "       0.00999748, 0.01001442, 0.00996861, 0.0100293 , 0.01003508,\n",
       "       0.01001499, 0.01005327, 0.00994187, 0.00995411, 0.01000185,\n",
       "       0.00996092, 0.01001032, 0.0099979 , 0.01001819, 0.01005453,\n",
       "       0.00999876, 0.0099688 , 0.00997128, 0.01006555, 0.0100433 ,\n",
       "       0.01000842, 0.01004547, 0.00999212, 0.00999569, 0.00999037,\n",
       "       0.01001048, 0.00997159, 0.00995841, 0.01001847, 0.00994431,\n",
       "       0.00993359, 0.00998814, 0.0100254 , 0.01001652, 0.00992505,\n",
       "       0.00993957, 0.01002752, 0.01002235, 0.00997444, 0.01004858,\n",
       "       0.00989277, 0.00995714, 0.01005671, 0.00994051, 0.01003763,\n",
       "       0.00998278, 0.00998413, 0.01002722, 0.01001286, 0.00998708])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_training_samples, axis = 0) # * norm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000004, 0.99999999, 1.00000004, ..., 0.99999994, 1.00000001,\n",
       "       0.99999998])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(new_gan_samples, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01006562, 0.01060201, 0.00939326, 0.01066261, 0.00839568,\n",
       "       0.00867846, 0.00986383, 0.00892806, 0.00922239, 0.01042323,\n",
       "       0.01241126, 0.00885244, 0.01135979, 0.01007721, 0.00952929,\n",
       "       0.01038234, 0.00929688, 0.01146677, 0.01178913, 0.00889552,\n",
       "       0.01077789, 0.01066141, 0.01132662, 0.01254065, 0.00970659,\n",
       "       0.00947724, 0.0093698 , 0.00739294, 0.00969986, 0.01285481,\n",
       "       0.00937918, 0.01069378, 0.00932177, 0.00928982, 0.01018118,\n",
       "       0.01037383, 0.00944713, 0.01054213, 0.01063923, 0.0090338 ,\n",
       "       0.01074361, 0.01037796, 0.01035835, 0.01001522, 0.00980194,\n",
       "       0.00775463, 0.01167995, 0.00846307, 0.01153496, 0.00901075,\n",
       "       0.00991259, 0.01049729, 0.01096462, 0.00910769, 0.01185234,\n",
       "       0.0101241 , 0.01097751, 0.00877353, 0.00893083, 0.0099851 ,\n",
       "       0.00880109, 0.01061159, 0.01036288, 0.01144762, 0.00914435,\n",
       "       0.00994262, 0.01064267, 0.0103603 , 0.00698218, 0.00967797,\n",
       "       0.00836856, 0.00885994, 0.01232335, 0.01006076, 0.00939223,\n",
       "       0.01152035, 0.00978426, 0.01046862, 0.00807506, 0.01051234,\n",
       "       0.00943158, 0.00994022, 0.01004638, 0.0106313 , 0.0092881 ,\n",
       "       0.01110692, 0.0112986 , 0.010334  , 0.01008421, 0.01216635,\n",
       "       0.00961286, 0.0084606 , 0.01049413, 0.00908176, 0.0090381 ,\n",
       "       0.00817612, 0.00788623, 0.01160228, 0.01026825, 0.0098418 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_gan_samples, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01014582, 0.0102711 , 0.00882925, 0.01018907, 0.00828433,\n",
       "       0.0086139 , 0.00955537, 0.00840725, 0.00875056, 0.00976004,\n",
       "       0.01159551, 0.00844249, 0.01055767, 0.00932698, 0.00885484,\n",
       "       0.00990069, 0.00868776, 0.01086327, 0.01125215, 0.00860167,\n",
       "       0.01061926, 0.0103265 , 0.01078569, 0.01223976, 0.00923272,\n",
       "       0.00916649, 0.00932103, 0.00744271, 0.00952182, 0.01232621,\n",
       "       0.00945573, 0.01052007, 0.00891913, 0.00886911, 0.00986315,\n",
       "       0.00925389, 0.00903887, 0.01024805, 0.01043448, 0.00877064,\n",
       "       0.01055862, 0.01001151, 0.00946554, 0.00948754, 0.00995993,\n",
       "       0.00720149, 0.01127206, 0.00869371, 0.01081135, 0.00863277,\n",
       "       0.00951941, 0.00949509, 0.010267  , 0.00853231, 0.011313  ,\n",
       "       0.00992862, 0.01050301, 0.00869316, 0.00838686, 0.00950613,\n",
       "       0.00846188, 0.01001403, 0.00992273, 0.01044736, 0.00881819,\n",
       "       0.0095602 , 0.01074458, 0.00987318, 0.00664912, 0.00911135,\n",
       "       0.00793333, 0.00840376, 0.01175566, 0.00990054, 0.00921754,\n",
       "       0.01110752, 0.00957108, 0.00984108, 0.00776912, 0.01025989,\n",
       "       0.00918235, 0.00968477, 0.00932874, 0.01014261, 0.00855202,\n",
       "       0.01057436, 0.01087332, 0.00990482, 0.00993501, 0.01170527,\n",
       "       0.00894686, 0.00813835, 0.00976838, 0.00872817, 0.00901234,\n",
       "       0.00769311, 0.00796953, 0.01118086, 0.01006868, 0.00939065])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(new_gan_samples,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00986713, 0.00992667, 0.00996256, 0.00988871, 0.00990136,\n",
       "       0.00984482, 0.00988819, 0.00985831, 0.0097691 , 0.00992449,\n",
       "       0.00987669, 0.00985547, 0.00982881, 0.00989234, 0.00987861,\n",
       "       0.00991642, 0.00990779, 0.00987469, 0.00992674, 0.00998985,\n",
       "       0.00991088, 0.00981389, 0.00991952, 0.00995936, 0.00989086,\n",
       "       0.00984153, 0.00998302, 0.00991277, 0.00997119, 0.00994237,\n",
       "       0.0099203 , 0.00993187, 0.00999846, 0.00990352, 0.00986004,\n",
       "       0.00990588, 0.00981828, 0.00987371, 0.01006198, 0.00996367,\n",
       "       0.00995127, 0.00980515, 0.00988595, 0.00991491, 0.0098223 ,\n",
       "       0.00986838, 0.00993312, 0.00988222, 0.00991782, 0.00988459,\n",
       "       0.00989312, 0.0098146 , 0.00982504, 0.00996198, 0.00999177,\n",
       "       0.00993004, 0.00999219, 0.00990355, 0.00991433, 0.00991172,\n",
       "       0.00984701, 0.00993675, 0.00987955, 0.00987176, 0.00997467,\n",
       "       0.00994622, 0.00991522, 0.00988618, 0.00996889, 0.00992506,\n",
       "       0.00990633, 0.00990064, 0.0099147 , 0.00996368, 0.00993043,\n",
       "       0.00995522, 0.00981456, 0.00986559, 0.00991002, 0.00980862,\n",
       "       0.00976572, 0.00991238, 0.00991786, 0.00989673, 0.00986321,\n",
       "       0.0098351 , 0.00988344, 0.00993354, 0.0099559 , 0.00993792,\n",
       "       0.00978932, 0.00987443, 0.00995616, 0.00984188, 0.00993674,\n",
       "       0.00988704, 0.00989194, 0.00990532, 0.00984673, 0.00986365])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(new_training_samples,axis=0)"
   ]
  },
  {
=======
>>>>>>> 44419ca6f155fcc7ac2630dc606bc45259c0f7c6
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
