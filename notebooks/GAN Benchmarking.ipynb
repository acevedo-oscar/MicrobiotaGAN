{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import copy \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(data, n:float, seed=0):\n",
    "    dummy_labels = np.ones(data.shape[0])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, dummy_labels, test_size=n, random_state=seed)\n",
    "    return [X_train, X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/acevedo/Desktop/Current_GAN/MicrobiotaGAN/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../data/DS_1.csv', header=None) .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data = pd.read_csv('../data/gan_dirichlet_1.csv', header=None) .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_dataset(my_data, n=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(my_data ==0))\n",
    "print(np.sum(gan_data ==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error de Validacion\n",
    "\n",
    "En esta parte hay que definir un error para nuestra GAN.\n",
    "\n",
    "## Clasificacion \n",
    "+ Para problemas de **clasificacion** una medida del error puede ser **clasificaciones correctas/numero total de clasificacones**\n",
    "+ Para problemas de clasificacion multi clase existe una perdida logaritmica definida como: $$\\frac{-1}{N} \\mathop{\\sum_{i=1}^{N}\\sum_{j=1}^{M}} y_{ij}*log(p_{ij})$$\n",
    "\n",
    "Donde:\n",
    "+ $y_{ij}$ indica si la muestra i pertenece a la clase j\n",
    "+ $p_{ij}$  es la probabiliad de que la muestra i pertenezca a la calse j \n",
    "\n",
    "+ **F1 Score** : $$2 \\times \\frac{1}{ \\frac{1}{precision} + \\frac{1}{recall}}$$. Precision y recall se definen en terminos de TruePositives, FalsePositives y FalseNegatives\n",
    "\n",
    "## Regresion\n",
    "\n",
    "+ Mean Absolute Error\n",
    "+ Mean Squared Error\n",
    "\n",
    "## Medidas para las GANS\n",
    "\n",
    "En el caso de las GANs, la funcion objetivo o de perdida mide que tan bien el generador enga√±a al discriminador. Entonces, esta no nos dice mucho acerca de que tan reaslaticas o diversas son las muestras generadas por la GAN.\n",
    "\n",
    "Para el caso de **GAN de imagenes**, hay dos medidas del rendimiento de una gan, el Inception Score y el Frechet Inception Distance. (https://medium.com/@jonathan_hui/gan-how-to-measure-gan-performance-64b988c47732)\n",
    "\n",
    "**Una buena GAN es una que genera muestras diversas y realistas**. En el caso de las imagenes, no es trivial hacer que una computadora te diga que tan realistas es una imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapted Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import scipy\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy import inf\n",
    "from copy import copy \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from get_disc_score import get_disc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path =  \"../model/dir1/my_gan.ckpt\"\n",
    "\n",
    "def pseudo_is_score(data, restore_path):\n",
    "    x = get_disc_score(val, restore_path )\n",
    "    \n",
    "    logits = np.exp(x)\n",
    "    \n",
    "    py = np.mean(logits, keepdims = True)\n",
    "    \n",
    "    # pxy_k = logits[k,:]\n",
    "    \n",
    "    print(py.shape)\n",
    "    print( logits.shape)\n",
    "    \n",
    "    assert py.shape[1] == logits.shape[1]\n",
    "    \n",
    "    N = data.shape[0]\n",
    "    \n",
    "    #pre_score = [DKL( logits[k,:], py ) for k in range(N) ]\n",
    "    \n",
    "    #pre_score = np.array(pre_score)\n",
    "    return py, logits\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = my_data[1:5,:] #.reshape(1,100)\n",
    "\n",
    "py, logits = pseudo_is_score(val, model_path)\n",
    "py = py.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = logits[0,:]\n",
    "\n",
    "b = py\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "DKL(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly use DKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DKL(pk_, qk_, epsilon = 0.01):\n",
    "    \n",
    "    \"\"\"   \n",
    "    n = pk.shape[0]    \n",
    "    normed_pk = normalize(pk.reshape(1,n),  norm='l1')\n",
    "    normed_qk = normalize(qk.reshape(1,n), norm='l1')\n",
    "    print(normed_pk)  \n",
    "    \"\"\"\n",
    "    pk = copy(pk_)\n",
    "    qk = copy(qk_)\n",
    "    \n",
    "    #print(pk.shape)\n",
    "    a = np.sum(pk ==0)\n",
    "    b = np.sum(qk ==0)\n",
    "    # assert a ==0 and b ==0\n",
    "    \n",
    "    #if  a !=0 or b !=0:\n",
    "        #print(\"Padding Zeroes\")\n",
    "\n",
    "    # Beware  zeros\n",
    "    pk[pk==0] = epsilon\n",
    "    qk[qk==0] = epsilon\n",
    "    \n",
    "    return scipy.stats.entropy(pk,qk)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_data.shape)\n",
    "print(gan_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n =10000\n",
    "a = gan_data[0:n,:].mean(axis=0)\n",
    "b = my_data [0:n,:].mean(axis=0)\n",
    "\n",
    "print(np.sum(a ==0))\n",
    "print(np.sum(b ==0))\n",
    "\n",
    "DKL(b,a) == DKL(b,a)\n",
    "\n",
    "DKL(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gan_data[0:n,:]\n",
    "b = my_data [0:n,:]\n",
    "\n",
    "print(np.sum(a ==0))\n",
    "print(np.sum(b ==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = [DKL(a[k,:], b[k,:]) for k in range(n)]\n",
    "entropy = np.array(entropy)\n",
    "np.sum(entropy== inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "#print(a[k,:])\n",
    "#print(b[k,:])\n",
    "#print(scipy.spatial.distance.euclidean(a[k,:], b[k,:]))\n",
    "\n",
    "print(a[k,:].sum())\n",
    "DKL(a[k,:], b[k,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#entropy[entropy == inf] = 0\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "\n",
    "for k in range(10000):\n",
    "    if entropy[k] == inf:\n",
    "        index_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = index_list[20]\n",
    "\n",
    "\n",
    "DKL(a[k,:], b[k,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(index_list)):\n",
    "    k = index_list[e]\n",
    "    print(distance.jensenshannon(a[k,:], b[k,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 87\n",
    "\n",
    "print(a[k,:].std())\n",
    "print(b[k,:].std())\n",
    "print(a[k,:].sum())\n",
    "\n",
    "DKL(a[k,:], b[k,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = distance.jensenshannon(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b + np.random.normal(0,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "entropy2 = [distance.jensenshannon(a[k,:], b[k,:]) for k in range(n)]\n",
    "entropy2 = np.array(entropy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy4 = [DKL(a[k,:],b[k,:]) for k in range(n)]\n",
    "entropy4 = np.array(entropy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = entropy4[entropy4 < 1E308]#.mean()\n",
    "temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =  b +0.1*np.random.normal(0,1,100)\n",
    "c.mean()\n",
    "\n",
    "c =0.8*(b+0.9)\n",
    "c.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy3 = [DKL(a[k,:],c[k,:]) for k in range(n)]\n",
    "entropy3 = np.array(entropy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy3[entropy3 < 1E308].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = entropy4[entropy4 < 1E308]#.mean()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)\n",
    "np.mean(np.exp(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
